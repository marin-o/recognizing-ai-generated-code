{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2b9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33f29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosa/diplomska/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import CoDeTM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69451b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test  = CoDeTM4('../../data/').get_dataset(['train','val','test'], columns='all', dynamic_split_sizing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c887dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6030553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "codet = concatenate_datasets([train, val, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c36f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_sitter_python as tspython\n",
    "import tree_sitter_cpp as tscpp\n",
    "import tree_sitter_java as tsjava\n",
    "from tree_sitter import Parser, Language\n",
    "\n",
    "TS_PYTHON = Language(tspython.language())\n",
    "TS_JAVA = Language(tsjava.language())\n",
    "TS_CPP = Language(tscpp.language())\n",
    "\n",
    "PYTHON_PARSER, JAVA_PARSER, CPP_PARSER = Parser(language=TS_PYTHON), Parser(language=TS_JAVA), Parser(language=TS_CPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2085170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "UniXCoder model loaded successfully\n",
      "UniXCoder model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Install and import UniXCoder\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Load UniXCoder model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"UniXCoder model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56003a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser(language):\n",
    "    match language:\n",
    "        case 'python':\n",
    "            return PYTHON_PARSER\n",
    "        case 'java':\n",
    "            return JAVA_PARSER\n",
    "        case 'cpp':\n",
    "            return CPP_PARSER\n",
    "    raise ValueError(f\"Unsupported language: {language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c0666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(sample, code_key='cleaned_code'):\n",
    "    language = sample['language']\n",
    "    parser = get_parser(language)\n",
    "    tree = parser.parse(bytes(sample[code_key], 'utf-8'))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5718113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_text(node, source_code_bytes):\n",
    "    \"\"\"Extract the text content of a node from the source code.\"\"\"\n",
    "    return source_code_bytes[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a871af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for root node types and special embeddings\n",
    "def create_root_embedding(node, language):\n",
    "    \"\"\"Create a special embedding for root nodes based on node type and language.\"\"\"\n",
    "    # Create a simple text representation for the root\n",
    "    root_text = f\"<ROOT_{language.upper()}_{node.type}>\"\n",
    "    \n",
    "    # Generate embedding for this special token\n",
    "    inputs = tokenizer(root_text, return_tensors=\"pt\", max_length=32, \n",
    "                      truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4440a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unixcoder_embedding(text, max_length=512, is_root=False, node=None, language=None):\n",
    "    \"\"\"Generate UniXCoder embedding for a given text.\"\"\"\n",
    "    if is_root and node is not None and language is not None:\n",
    "        # For root nodes, create a special embedding based on node type and language\n",
    "        return create_root_embedding(node, language)\n",
    "    \n",
    "    if not text.strip():\n",
    "        # Return zero embedding for empty text\n",
    "        return torch.zeros(768)  # UniXCoder base has 768 dimensions\n",
    "    \n",
    "    # Tokenize and truncate if necessary\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, \n",
    "                      truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use the [CLS] token embedding (first token)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34097f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unixcoder_embeddings_batch(texts, max_length=512, batch_size=32):\n",
    "    \"\"\"Generate UniXCoder embeddings for a batch of texts efficiently.\"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Filter out empty texts and keep track of indices\n",
    "        non_empty_texts = []\n",
    "        text_indices = []\n",
    "        for j, text in enumerate(batch_texts):\n",
    "            if text.strip():\n",
    "                non_empty_texts.append(text)\n",
    "                text_indices.append(j)\n",
    "        \n",
    "        if not non_empty_texts:\n",
    "            # All texts in this batch are empty\n",
    "            batch_embeddings = [torch.zeros(768) for _ in batch_texts]\n",
    "        else:\n",
    "            # Batch tokenize non-empty texts\n",
    "            inputs = tokenizer(non_empty_texts, return_tensors=\"pt\", max_length=max_length, \n",
    "                              truncation=True, padding=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "            \n",
    "            # Create result list with zeros for empty texts\n",
    "            batch_embeddings = []\n",
    "            embedding_idx = 0\n",
    "            for j, text in enumerate(batch_texts):\n",
    "                if j in text_indices:\n",
    "                    batch_embeddings.append(embeddings[embedding_idx])\n",
    "                    embedding_idx += 1\n",
    "                else:\n",
    "                    batch_embeddings.append(torch.zeros(768))\n",
    "        \n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64ee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from typing import List, Tuple, Dict\n",
    "from torch import tensor, long as tlong\n",
    "from tree_sitter import TreeCursor\n",
    "\n",
    "def tree_to_graph_with_embeddings(cursor: TreeCursor, source_code_bytes: bytes, \n",
    "                                 language: str,\n",
    "                                 id_map: Dict = None, next_id: int = 0, \n",
    "                                 edges: List[Tuple[int, int]] = None,\n",
    "                                 node_embeddings: List = None,\n",
    "                                 is_root_call: bool = True) -> Tuple[List[Tuple[int, int]], Dict, int, List]:\n",
    "    if edges is None:\n",
    "        edges = []\n",
    "    if id_map is None:\n",
    "        id_map = {}\n",
    "    if node_embeddings is None:\n",
    "        node_embeddings = []\n",
    "\n",
    "    # Assign ID to current node\n",
    "    if cursor.node not in id_map:\n",
    "        id_map[cursor.node] = next_id\n",
    "        # Get node text and generate embedding\n",
    "        node_text = get_node_text(cursor.node, source_code_bytes)\n",
    "        # Check if this is the root node (first call to the function)\n",
    "        if is_root_call:\n",
    "            embedding = get_unixcoder_embedding(node_text, is_root=True, node=cursor.node, language=language)\n",
    "        else:\n",
    "            embedding = get_unixcoder_embedding(node_text, is_root=False)\n",
    "        node_embeddings.append(embedding)\n",
    "        next_id += 1\n",
    "    \n",
    "    current_id = id_map[cursor.node]\n",
    "\n",
    "    if cursor.goto_first_child():\n",
    "        # Process first child\n",
    "        if cursor.node not in id_map:\n",
    "            id_map[cursor.node] = next_id\n",
    "            node_text = get_node_text(cursor.node, source_code_bytes)\n",
    "            embedding = get_unixcoder_embedding(node_text, is_root=False)\n",
    "            node_embeddings.append(embedding)\n",
    "            next_id += 1\n",
    "        child_id = id_map[cursor.node]\n",
    "        edges.append((current_id, child_id))\n",
    "        edges, id_map, next_id, node_embeddings = tree_to_graph_with_embeddings(\n",
    "            cursor, source_code_bytes, language, id_map, next_id, edges, node_embeddings, is_root_call=False)\n",
    "        \n",
    "        # Process siblings\n",
    "        while cursor.goto_next_sibling():\n",
    "            if cursor.node not in id_map:\n",
    "                id_map[cursor.node] = next_id\n",
    "                node_text = get_node_text(cursor.node, source_code_bytes)\n",
    "                embedding = get_unixcoder_embedding(node_text, is_root=False)\n",
    "                node_embeddings.append(embedding)\n",
    "                next_id += 1\n",
    "            child_id = id_map[cursor.node]\n",
    "            edges.append((current_id, child_id))\n",
    "            edges, id_map, next_id, node_embeddings = tree_to_graph_with_embeddings(\n",
    "                cursor, source_code_bytes, language, id_map, next_id, edges, node_embeddings, is_root_call=False)\n",
    "        \n",
    "        cursor.goto_parent()\n",
    "\n",
    "    return edges, id_map, next_id, node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce7fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb3d0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_with_unixcoder(sample):\n",
    "    tree = create_tree(sample)\n",
    "    source_code_bytes = sample['cleaned_code'].encode('utf-8')\n",
    "    language = sample['language']\n",
    "    \n",
    "    edges, id_map, _, node_embeddings = tree_to_graph_with_embeddings(\n",
    "        tree.walk(), source_code_bytes, language)\n",
    "    \n",
    "    edge_index = tensor(edges, dtype=tlong).t().contiguous() if edges else tensor([], dtype=tlong).reshape(2, 0)\n",
    "    \n",
    "    # Stack node embeddings to create feature matrix\n",
    "    if node_embeddings:\n",
    "        x = torch.stack(node_embeddings)\n",
    "    else:\n",
    "        # Fallback for empty graphs\n",
    "        x = torch.zeros((1, 768))  # UniXCoder embedding dimension\n",
    "    \n",
    "    y = tensor([sample['target_binary']], dtype=tlong)\n",
    "    graph_features = tensor(list(sample['features'].values()))\n",
    "    \n",
    "    metadata = {\n",
    "        'language': sample['language'],\n",
    "        'target': sample['target'],\n",
    "        'target_binary': sample['target_binary'],\n",
    "        'code': sample['code'],\n",
    "        'cleaned_code': sample['cleaned_code']\n",
    "    }\n",
    "    \n",
    "    data = Data(\n",
    "        x=x, \n",
    "        y=y, \n",
    "        edge_index=edge_index, \n",
    "        graph_features=graph_features,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296ffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nodes_and_texts(cursor, source_code_bytes, language, nodes_info=None, is_root_call=True):\n",
    "    \"\"\"Collect all nodes and their texts in a single traversal.\"\"\"\n",
    "    if nodes_info is None:\n",
    "        nodes_info = []\n",
    "    \n",
    "    node_text = get_node_text(cursor.node, source_code_bytes)\n",
    "    if is_root_call:\n",
    "        # Special handling for root\n",
    "        root_text = f\"<ROOT_{language.upper()}_{cursor.node.type}>\"\n",
    "        nodes_info.append((cursor.node, root_text, True))\n",
    "    else:\n",
    "        nodes_info.append((cursor.node, node_text, False))\n",
    "    \n",
    "    if cursor.goto_first_child():\n",
    "        collect_nodes_and_texts(cursor, source_code_bytes, language, nodes_info, False)\n",
    "        while cursor.goto_next_sibling():\n",
    "            collect_nodes_and_texts(cursor, source_code_bytes, language, nodes_info, False)\n",
    "        cursor.goto_parent()\n",
    "    \n",
    "    return nodes_info\n",
    "\n",
    "def build_graph_structure(cursor, id_map=None, next_id=0, edges=None):\n",
    "    \"\"\"Build the graph structure (edges and node mapping) without embeddings.\"\"\"\n",
    "    if edges is None:\n",
    "        edges = []\n",
    "    if id_map is None:\n",
    "        id_map = {}\n",
    "\n",
    "    # Assign ID to current node\n",
    "    if cursor.node not in id_map:\n",
    "        id_map[cursor.node] = next_id\n",
    "        next_id += 1\n",
    "    \n",
    "    current_id = id_map[cursor.node]\n",
    "\n",
    "    if cursor.goto_first_child():\n",
    "        # Process first child\n",
    "        if cursor.node not in id_map:\n",
    "            id_map[cursor.node] = next_id\n",
    "            next_id += 1\n",
    "        child_id = id_map[cursor.node]\n",
    "        edges.append((current_id, child_id))\n",
    "        edges, id_map, next_id = build_graph_structure(cursor, id_map, next_id, edges)\n",
    "        \n",
    "        # Process siblings\n",
    "        while cursor.goto_next_sibling():\n",
    "            if cursor.node not in id_map:\n",
    "                id_map[cursor.node] = next_id\n",
    "                next_id += 1\n",
    "            child_id = id_map[cursor.node]\n",
    "            edges.append((current_id, child_id))\n",
    "            edges, id_map, next_id = build_graph_structure(cursor, id_map, next_id, edges)\n",
    "        \n",
    "        cursor.goto_parent()\n",
    "\n",
    "    return edges, id_map, next_id\n",
    "\n",
    "def create_graph_with_unixcoder_batch(sample):\n",
    "    \"\"\"Optimized graph creation using batch processing for embeddings.\"\"\"\n",
    "    tree = create_tree(sample)\n",
    "    source_code_bytes = sample['cleaned_code'].encode('utf-8')\n",
    "    language = sample['language']\n",
    "    \n",
    "    # First pass: collect all nodes and their texts\n",
    "    nodes_info = collect_nodes_and_texts(tree.walk(), source_code_bytes, language)\n",
    "    \n",
    "    # Extract texts for batch processing\n",
    "    texts = [text for _, text, _ in nodes_info]\n",
    "    \n",
    "    # Generate embeddings in batch\n",
    "    embeddings = get_unixcoder_embeddings_batch(texts)\n",
    "    \n",
    "    # Second pass: build graph structure\n",
    "    edges, id_map, _ = build_graph_structure(tree.walk())\n",
    "    \n",
    "    # Create node feature matrix using batch embeddings\n",
    "    # Sort nodes by their IDs to ensure correct ordering\n",
    "    node_embedding_pairs = []\n",
    "    for i, (node, _, _) in enumerate(nodes_info):\n",
    "        node_id = id_map[node]\n",
    "        node_embedding_pairs.append((node_id, embeddings[i]))\n",
    "    \n",
    "    # Sort by node ID and extract embeddings in correct order\n",
    "    node_embedding_pairs.sort(key=lambda x: x[0])\n",
    "    ordered_embeddings = [emb for _, emb in node_embedding_pairs]\n",
    "    \n",
    "    edge_index = tensor(edges, dtype=tlong).t().contiguous() if edges else tensor([], dtype=tlong).reshape(2, 0)\n",
    "    x = torch.stack(ordered_embeddings) if ordered_embeddings else torch.zeros((1, 768))\n",
    "    \n",
    "    y = tensor([sample['target_binary']], dtype=tlong)\n",
    "    graph_features = tensor(list(sample['features'].values()))\n",
    "    \n",
    "    metadata = {\n",
    "        'language': sample['language'],\n",
    "        'target': sample['target'],\n",
    "        'target_binary': sample['target_binary'],\n",
    "        'code': sample['code'],\n",
    "        'cleaned_code': sample['cleaned_code']\n",
    "    }\n",
    "    \n",
    "    return Data(x=x, y=y, edge_index=edge_index, graph_features=graph_features, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4323e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphs_with_unixcoder_optimized(dataset, desc_keyword):\n",
    "    \"\"\"Create graphs using optimized batch processing for embeddings.\"\"\"\n",
    "    graphs = []\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset, desc=f'Creating {desc_keyword} graphs with UniXCoder (optimized)')):\n",
    "        try:\n",
    "            data = create_graph_with_unixcoder_batch(sample)\n",
    "            graphs.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            # Skip problematic samples\n",
    "            continue\n",
    "\n",
    "    return graphs\n",
    "\n",
    "# Keep the old function for comparison\n",
    "def create_graphs_with_unixcoder(dataset, desc_keyword):\n",
    "    \"\"\"Original (slower) graph creation function.\"\"\"\n",
    "    graphs = []\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset, desc=f'Creating {desc_keyword} graphs with UniXCoder')):\n",
    "        try:\n",
    "            data = create_graph_with_unixcoder(sample)\n",
    "            graphs.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            # Skip problematic samples\n",
    "            continue\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "598a0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimization on small subset...\n",
      "Testing original method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating test_original graphs with UniXCoder: 100%|██████████| 10/10 [00:28<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimized method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating test_optimized graphs with UniXCoder (optimized): 100%|██████████| 10/10 [00:06<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance comparison:\n",
      "Original method: 28.23 seconds for 10 graphs\n",
      "Optimized method: 6.14 seconds for 10 graphs\n",
      "Speedup: 4.60x\n",
      "\n",
      "Verification:\n",
      "Original graph shape: torch.Size([2067, 768])\n",
      "Optimized graph shape: torch.Size([2067, 768])\n",
      "Shapes match: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the optimization on a small subset\n",
    "import time\n",
    "\n",
    "print(\"Testing optimization on small subset...\")\n",
    "test_subset = train.select(range(10))  # Test with 10 samples\n",
    "\n",
    "# Test original method\n",
    "print(\"Testing original method...\")\n",
    "start_time = time.time()\n",
    "graphs_original = create_graphs_with_unixcoder(test_subset, 'test_original')\n",
    "original_time = time.time() - start_time\n",
    "\n",
    "# Test optimized method\n",
    "print(\"Testing optimized method...\")\n",
    "start_time = time.time()\n",
    "graphs_optimized = create_graphs_with_unixcoder_optimized(test_subset, 'test_optimized')\n",
    "optimized_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nPerformance comparison:\")\n",
    "print(f\"Original method: {original_time:.2f} seconds for {len(graphs_original)} graphs\")\n",
    "print(f\"Optimized method: {optimized_time:.2f} seconds for {len(graphs_optimized)} graphs\")\n",
    "print(f\"Speedup: {original_time/optimized_time:.2f}x\")\n",
    "\n",
    "# Verify that results are similar\n",
    "if len(graphs_original) > 0 and len(graphs_optimized) > 0:\n",
    "    print(f\"\\nVerification:\")\n",
    "    print(f\"Original graph shape: {graphs_original[0].x.shape}\")\n",
    "    print(f\"Optimized graph shape: {graphs_optimized[0].x.shape}\")\n",
    "    print(f\"Shapes match: {graphs_original[0].x.shape == graphs_optimized[0].x.shape}\")\n",
    "\n",
    "del graphs_original, graphs_optimized  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19259443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train graphs with UniXCoder embeddings (full dataset - optimized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating train graphs with UniXCoder (optimized):   0%|          | 161/405069 [00:49<34:30:21,  3.26it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating train graphs with UniXCoder embeddings (full dataset - optimized)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     train_graphs_unixcoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_graphs_with_unixcoder_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     save(train_graphs_unixcoder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/codet_graphs/train_graphs_unixcoder.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_graphs_unixcoder)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m train graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mcreate_graphs_with_unixcoder_optimized\u001b[0;34m(dataset, desc_keyword)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataset, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdesc_keyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m graphs with UniXCoder (optimized)\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_graph_with_unixcoder_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         graphs\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[17], line 71\u001b[0m, in \u001b[0;36mcreate_graph_with_unixcoder_batch\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     68\u001b[0m texts \u001b[38;5;241m=\u001b[39m [text \u001b[38;5;28;01mfor\u001b[39;00m _, text, _ \u001b[38;5;129;01min\u001b[39;00m nodes_info]\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Generate embeddings in batch\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_unixcoder_embeddings_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Second pass: build graph structure\u001b[39;00m\n\u001b[1;32m     74\u001b[0m edges, id_map, _ \u001b[38;5;241m=\u001b[39m build_graph_structure(tree\u001b[38;5;241m.\u001b[39mwalk())\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mget_unixcoder_embeddings_batch\u001b[0;34m(texts, max_length, batch_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 31\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create result list with zeros for empty texts\u001b[39;00m\n\u001b[1;32m     34\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create directories if they don't exist\n",
    "import os\n",
    "os.makedirs('../../data/codet_graphs', exist_ok=True)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch import save\n",
    "\n",
    "# Option to process subset first (change to False for full dataset)\n",
    "USE_SUBSET = False\n",
    "SUBSET_SIZE = 5000  # Process first 5000 samples for testing\n",
    "\n",
    "if USE_SUBSET:\n",
    "    print(f\"Processing subset of {SUBSET_SIZE} samples first...\")\n",
    "    train_subset = train.select(range(min(SUBSET_SIZE, len(train))))\n",
    "    val_subset = val.select(range(min(SUBSET_SIZE, len(val))))  \n",
    "    test_subset = test.select(range(min(SUBSET_SIZE, len(test))))\n",
    "    \n",
    "    print(\"Creating train graphs with UniXCoder embeddings (subset)...\")\n",
    "    train_graphs_unixcoder = create_graphs_with_unixcoder_optimized(train_subset, 'train_subset')\n",
    "    save(train_graphs_unixcoder, '../../data/codet_graphs/train_graphs_unixcoder_subset.pt')\n",
    "    print(f\"Saved {len(train_graphs_unixcoder)} train graphs (subset)\")\n",
    "    del train_subset, train_graphs_unixcoder\n",
    "    \n",
    "    print(\"Creating validation graphs with UniXCoder embeddings (subset)...\")\n",
    "    val_graphs_unixcoder = create_graphs_with_unixcoder_optimized(val_subset, 'val_subset')\n",
    "    save(val_graphs_unixcoder, '../../data/codet_graphs/val_graphs_unixcoder_subset.pt')\n",
    "    print(f\"Saved {len(val_graphs_unixcoder)} validation graphs (subset)\")\n",
    "    del val_subset, val_graphs_unixcoder\n",
    "    \n",
    "    print(\"Creating test graphs with UniXCoder embeddings (subset)...\")\n",
    "    test_graphs_unixcoder = create_graphs_with_unixcoder_optimized(test_subset, 'test_subset')\n",
    "    save(test_graphs_unixcoder, '../../data/codet_graphs/test_graphs_unixcoder_subset.pt')\n",
    "    print(f\"Saved {len(test_graphs_unixcoder)} test graphs (subset)\")\n",
    "    del test_subset, test_graphs_unixcoder\n",
    "    \n",
    "    print(\"Subset processing completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Creating train graphs with UniXCoder embeddings (full dataset - optimized)...\")\n",
    "    train_graphs_unixcoder = create_graphs_with_unixcoder_optimized(train, 'train')\n",
    "    save(train_graphs_unixcoder, '../../data/codet_graphs/train_graphs_unixcoder.pt')\n",
    "    print(f\"Saved {len(train_graphs_unixcoder)} train graphs\")\n",
    "    del train, train_graphs_unixcoder\n",
    "    \n",
    "    print(\"Creating validation graphs with UniXCoder embeddings (full dataset - optimized)...\")\n",
    "    val_graphs_unixcoder = create_graphs_with_unixcoder_optimized(val, 'val')\n",
    "    save(val_graphs_unixcoder, '../../data/codet_graphs/val_graphs_unixcoder.pt')\n",
    "    print(f\"Saved {len(val_graphs_unixcoder)} validation graphs\")\n",
    "    del val, val_graphs_unixcoder\n",
    "    \n",
    "    print(\"Creating test graphs with UniXCoder embeddings (full dataset - optimized)...\")\n",
    "    test_graphs_unixcoder = create_graphs_with_unixcoder_optimized(test, 'test')\n",
    "    save(test_graphs_unixcoder, '../../data/codet_graphs/test_graphs_unixcoder.pt')\n",
    "    print(f\"Saved {len(test_graphs_unixcoder)} test graphs\")\n",
    "    del test, test_graphs_unixcoder\n",
    "    \n",
    "    print(\"All UniXCoder graph datasets have been created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aaaee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the created graphs\n",
    "from torch import load\n",
    "\n",
    "print(\"Testing loading of created graphs...\")\n",
    "train_graphs_unixcoder = load('../../data/codet_graphs/train_graphs_unixcoder.pt', weights_only=False)\n",
    "print(f\"Loaded {len(train_graphs_unixcoder)} training graphs\")\n",
    "print(f\"First graph shape: {train_graphs_unixcoder[0].x.shape}\")\n",
    "print(f\"Embedding dimension: {train_graphs_unixcoder[0].x.shape[1]}\")\n",
    "\n",
    "val_graphs_unixcoder = load('../../data/codet_graphs/val_graphs_unixcoder.pt', weights_only=False)\n",
    "print(f\"Loaded {len(val_graphs_unixcoder)} validation graphs\")\n",
    "\n",
    "test_graphs_unixcoder = load('../../data/codet_graphs/test_graphs_unixcoder.pt', weights_only=False)\n",
    "print(f\"Loaded {len(test_graphs_unixcoder)} test graphs\")\n",
    "\n",
    "print(\"All graphs loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample graph with UniXCoder embeddings\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_unixcoder_graph(data, figsize=(15, 10)):\n",
    "    # Convert to NetworkX graph\n",
    "    G = to_networkx(data, to_undirected=False)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create tree layout manually\n",
    "    pos = {}\n",
    "    \n",
    "    # Find root (node with no incoming edges)\n",
    "    root = 0\n",
    "    for node in G.nodes():\n",
    "        if G.in_degree(node) == 0:\n",
    "            root = node\n",
    "            break\n",
    "    \n",
    "    # Assign positions level by level\n",
    "    levels = {}\n",
    "    queue = [(root, 0)]\n",
    "    \n",
    "    while queue:\n",
    "        node, level = queue.pop(0)\n",
    "        levels[node] = level\n",
    "        \n",
    "        # Add children to next level\n",
    "        for child in G.successors(node):\n",
    "            queue.append((child, level + 1))\n",
    "    \n",
    "    # Group nodes by level\n",
    "    level_groups = {}\n",
    "    for node, level in levels.items():\n",
    "        if level not in level_groups:\n",
    "            level_groups[level] = []\n",
    "        level_groups[level].append(node)\n",
    "    \n",
    "    # Position nodes\n",
    "    for level, nodes in level_groups.items():\n",
    "        for i, node in enumerate(nodes):\n",
    "            x = i - len(nodes) / 2  # Center nodes horizontally\n",
    "            y = -level  # Higher levels at top\n",
    "            pos[node] = (x, y)\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=True, \n",
    "            node_color='lightgreen', node_size=300, arrows=True, \n",
    "            font_size=8)\n",
    "    \n",
    "    plt.title(f\"AST Tree with UniXCoder Embeddings\\nNodes: {data.x.shape[0]}, Embedding dim: {data.x.shape[1]}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some metadata\n",
    "    print(f\"Language: {data.metadata['language']}\")\n",
    "    print(f\"Target: {data.metadata['target']}\")\n",
    "    print(f\"Code snippet (first 200 chars):\\n{data.metadata['cleaned_code'][:200]}...\")\n",
    "\n",
    "# Visualize the first graph\n",
    "if len(train_graphs_unixcoder) > 0:\n",
    "    visualize_unixcoder_graph(train_graphs_unixcoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3918b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
